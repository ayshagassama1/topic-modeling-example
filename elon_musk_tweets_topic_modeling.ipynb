{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1400f27a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.2.5)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2021.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\hp\\appdata\\roaming\\python\\python39\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (1.19.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064bce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca301ec6",
   "metadata": {},
   "source": [
    "# On charge les données depuis un fichier csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f31372",
   "metadata": {},
   "source": [
    "# Elon Musk tweets dataset\n",
    "https://www.kaggle.com/datasets/yasirabdaali/elon-musk-tweets-dataset-17k\n",
    "Ce dataset contient 17 000 tweets d'Elon Musk, le fondateur de Tesla et SpaceX. Notre objectif est de faire un topic modeling sur ces tweets afin de voir quels sont les sujets qui sont abordés dans les tweets d'Elon Musk.\n",
    "Les features sont les suivantes:\n",
    "* Date Created\n",
    "* Number of Likes\n",
    "* Source of Tweet\n",
    "* Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "587b98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = pd.read_csv(\"elonmusk.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7419d2",
   "metadata": {},
   "source": [
    "# Nettoyage des données\n",
    "* On commence par supprimer les colonnes qui ne nous intéressent pas pour notre analyse(la date du tweet, le nombre de likes et la source du tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a9e2b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@teslaownersSV @cb_doge @Tesla @mayemusk I gue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@cb_doge @Tesla @mayemusk Still doing same thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Looks good to roll out to all Tesla owners wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Tesla__Mania @WholeMarsBlog That is probably ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@WholeMarsBlog Real-world validation &amp;amp; bil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17432</th>\n",
       "      <td>That was a total non sequitur btw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17433</th>\n",
       "      <td>Great Voltaire quote, arguably better than Twa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17434</th>\n",
       "      <td>I made the volume on the Model S http://t.co/w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17435</th>\n",
       "      <td>Went to Iceland on Sat to ride bumper cars on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17436</th>\n",
       "      <td>Please ignore prior tweets, as that was someon...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17437 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Tweets\n",
       "0      @teslaownersSV @cb_doge @Tesla @mayemusk I gue...\n",
       "1      @cb_doge @Tesla @mayemusk Still doing same thi...\n",
       "2      Looks good to roll out to all Tesla owners wit...\n",
       "3      @Tesla__Mania @WholeMarsBlog That is probably ...\n",
       "4      @WholeMarsBlog Real-world validation &amp; bil...\n",
       "...                                                  ...\n",
       "17432                  That was a total non sequitur btw\n",
       "17433  Great Voltaire quote, arguably better than Twa...\n",
       "17434  I made the volume on the Model S http://t.co/w...\n",
       "17435  Went to Iceland on Sat to ride bumper cars on ...\n",
       "17436  Please ignore prior tweets, as that was someon...\n",
       "\n",
       "[17437 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datas = datas.drop(columns=['Date Created', 'Number of Likes', 'Source of Tweet'])\n",
    "datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a8745c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (3.3.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (60.2.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.0.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.4.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (4.64.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.0.7)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.9 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (1.19.5)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.14 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from spacy) (8.0.17)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->spacy) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906bffc4",
   "metadata": {},
   "source": [
    "* Suppression des mots vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f47e438",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f26c05",
   "metadata": {},
   "source": [
    " On charge les stopwords en anglais et on y ajoute les expressions qu'il utilise souvent dans ses tweets (exemple woohoo, cool, etc...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76ff3927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "# liste des mots vides en anglais\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "stop_words.add(\"woohoo\")\n",
    "stop_words.add(\"co\")\n",
    "stop_words.add(\"true\")\n",
    "stop_words.add(\"amp\")\n",
    "stop_words.add(\"rt\")\n",
    "stop_words.add(\"ok\")\n",
    "stop_words.add(\"yes\")\n",
    "stop_words.add(\"um\")\n",
    "stop_words.add(\"yup\")\n",
    "stop_words.add(\"maybe\")\n",
    "stop_words.add(\"good\")\n",
    "stop_words.add(\"thanks\")\n",
    "stop_words.add(\"awesome\")\n",
    "stop_words.add(\"yeah\")\n",
    "stop_words.add(\"like\")\n",
    "stop_words.add(\"haha\")\n",
    "stop_words.add(\"cool\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26353e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\"'d\",\n",
       " \"'ll\",\n",
       " \"'m\",\n",
       " \"'re\",\n",
       " \"'s\",\n",
       " \"'ve\",\n",
       " 'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'across',\n",
       " 'after',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'all',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'already',\n",
       " 'also',\n",
       " 'although',\n",
       " 'always',\n",
       " 'am',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'anyhow',\n",
       " 'anyone',\n",
       " 'anything',\n",
       " 'anyway',\n",
       " 'anywhere',\n",
       " 'are',\n",
       " 'around',\n",
       " 'as',\n",
       " 'at',\n",
       " 'awesome',\n",
       " 'back',\n",
       " 'be',\n",
       " 'became',\n",
       " 'because',\n",
       " 'become',\n",
       " 'becomes',\n",
       " 'becoming',\n",
       " 'been',\n",
       " 'before',\n",
       " 'beforehand',\n",
       " 'behind',\n",
       " 'being',\n",
       " 'below',\n",
       " 'beside',\n",
       " 'besides',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'but',\n",
       " 'by',\n",
       " 'ca',\n",
       " 'call',\n",
       " 'can',\n",
       " 'cannot',\n",
       " 'co',\n",
       " 'cool',\n",
       " 'could',\n",
       " 'did',\n",
       " 'do',\n",
       " 'does',\n",
       " 'doing',\n",
       " 'done',\n",
       " 'down',\n",
       " 'due',\n",
       " 'during',\n",
       " 'each',\n",
       " 'eight',\n",
       " 'either',\n",
       " 'eleven',\n",
       " 'else',\n",
       " 'elsewhere',\n",
       " 'empty',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everyone',\n",
       " 'everything',\n",
       " 'everywhere',\n",
       " 'except',\n",
       " 'few',\n",
       " 'fifteen',\n",
       " 'fifty',\n",
       " 'first',\n",
       " 'five',\n",
       " 'for',\n",
       " 'former',\n",
       " 'formerly',\n",
       " 'forty',\n",
       " 'four',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'further',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'good',\n",
       " 'had',\n",
       " 'haha',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'hence',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hereafter',\n",
       " 'hereby',\n",
       " 'herein',\n",
       " 'hereupon',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'however',\n",
       " 'hundred',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'indeed',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'keep',\n",
       " 'last',\n",
       " 'latter',\n",
       " 'latterly',\n",
       " 'least',\n",
       " 'less',\n",
       " 'like',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'may',\n",
       " 'maybe',\n",
       " 'me',\n",
       " 'meanwhile',\n",
       " 'might',\n",
       " 'mine',\n",
       " 'more',\n",
       " 'moreover',\n",
       " 'most',\n",
       " 'mostly',\n",
       " 'move',\n",
       " 'much',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " \"n't\",\n",
       " 'name',\n",
       " 'namely',\n",
       " 'neither',\n",
       " 'never',\n",
       " 'nevertheless',\n",
       " 'next',\n",
       " 'nine',\n",
       " 'no',\n",
       " 'nobody',\n",
       " 'none',\n",
       " 'noone',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'nowhere',\n",
       " 'n‘t',\n",
       " 'n’t',\n",
       " 'of',\n",
       " 'off',\n",
       " 'often',\n",
       " 'ok',\n",
       " 'on',\n",
       " 'once',\n",
       " 'one',\n",
       " 'only',\n",
       " 'onto',\n",
       " 'or',\n",
       " 'other',\n",
       " 'others',\n",
       " 'otherwise',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 'part',\n",
       " 'per',\n",
       " 'perhaps',\n",
       " 'please',\n",
       " 'put',\n",
       " 'quite',\n",
       " 'rather',\n",
       " 're',\n",
       " 'really',\n",
       " 'regarding',\n",
       " 'rt',\n",
       " 'same',\n",
       " 'say',\n",
       " 'see',\n",
       " 'seem',\n",
       " 'seemed',\n",
       " 'seeming',\n",
       " 'seems',\n",
       " 'serious',\n",
       " 'several',\n",
       " 'she',\n",
       " 'should',\n",
       " 'show',\n",
       " 'side',\n",
       " 'since',\n",
       " 'six',\n",
       " 'sixty',\n",
       " 'so',\n",
       " 'some',\n",
       " 'somehow',\n",
       " 'someone',\n",
       " 'something',\n",
       " 'sometime',\n",
       " 'sometimes',\n",
       " 'somewhere',\n",
       " 'still',\n",
       " 'such',\n",
       " 'take',\n",
       " 'ten',\n",
       " 'than',\n",
       " 'thanks',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'thence',\n",
       " 'there',\n",
       " 'thereafter',\n",
       " 'thereby',\n",
       " 'therefore',\n",
       " 'therein',\n",
       " 'thereupon',\n",
       " 'these',\n",
       " 'they',\n",
       " 'third',\n",
       " 'this',\n",
       " 'those',\n",
       " 'though',\n",
       " 'three',\n",
       " 'through',\n",
       " 'throughout',\n",
       " 'thru',\n",
       " 'thus',\n",
       " 'to',\n",
       " 'together',\n",
       " 'too',\n",
       " 'top',\n",
       " 'toward',\n",
       " 'towards',\n",
       " 'true',\n",
       " 'twelve',\n",
       " 'twenty',\n",
       " 'two',\n",
       " 'um',\n",
       " 'under',\n",
       " 'unless',\n",
       " 'until',\n",
       " 'up',\n",
       " 'upon',\n",
       " 'us',\n",
       " 'used',\n",
       " 'using',\n",
       " 'various',\n",
       " 'very',\n",
       " 'via',\n",
       " 'was',\n",
       " 'we',\n",
       " 'well',\n",
       " 'were',\n",
       " 'what',\n",
       " 'whatever',\n",
       " 'when',\n",
       " 'whence',\n",
       " 'whenever',\n",
       " 'where',\n",
       " 'whereafter',\n",
       " 'whereas',\n",
       " 'whereby',\n",
       " 'wherein',\n",
       " 'whereupon',\n",
       " 'wherever',\n",
       " 'whether',\n",
       " 'which',\n",
       " 'while',\n",
       " 'whither',\n",
       " 'who',\n",
       " 'whoever',\n",
       " 'whole',\n",
       " 'whom',\n",
       " 'whose',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'within',\n",
       " 'without',\n",
       " 'woohoo',\n",
       " 'would',\n",
       " 'yeah',\n",
       " 'yes',\n",
       " 'yet',\n",
       " 'you',\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'yup',\n",
       " '‘d',\n",
       " '‘ll',\n",
       " '‘m',\n",
       " '‘re',\n",
       " '‘s',\n",
       " '‘ve',\n",
       " '’d',\n",
       " '’ll',\n",
       " '’m',\n",
       " '’re',\n",
       " '’s',\n",
       " '’ve'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7fe1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b649e983",
   "metadata": {},
   "source": [
    "# Fonction de nettoyage des tweets\n",
    "* On supprime les mots commençant par un @ car ce sont des mentions à d'autres utilisateurs\n",
    "* On supprime les liens\n",
    "* On supprime les caractères spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "946ed504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour le pré-traitement des textes\n",
    "def preprocess(list_text):\n",
    "    clean_text = []\n",
    "    for text in list_text:\n",
    "        text = str(text).strip().lower()\n",
    "        doc = nlp(text)\n",
    "        token_list = []\n",
    "        for word in doc:\n",
    "            # (str(word).isdigit() == False):\n",
    "            if (str(word).lower() not in stop_words) and (word.is_punct == False) and (re.search('@+.|[0-9]|https*|http*', str(word)) == None) and  (str(word).isascii() == True):\n",
    "                token_list.append(word.text)\n",
    "        clean_text.append(' '.join(token_list))\n",
    "    return clean_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25866dac",
   "metadata": {},
   "source": [
    "On applique la fonction de nettoyage sur les tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb08e179",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_text = preprocess(datas['Tweets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff0a786",
   "metadata": {},
   "source": [
    "## Résultat du nettoyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff08c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['guess joe mode quieter',\n",
       " 'thing bigger',\n",
       " 'looks roll tesla owners cars',\n",
       " 'probably right order magnitude',\n",
       " 'real world validation billions miles real world training fsd superhuman',\n",
       " '',\n",
       " 'sigh',\n",
       " 'fsd beta rolling note priority safety expect overly cautious especially pedestrians',\n",
       " 'falcon arching orbit',\n",
       " 'obvious limit rocket reflight far',\n",
       " 'instagram envy amplifier',\n",
       " '',\n",
       " 'team found bug causing delay detecting pedestrians m. fixed rolling tonight',\n",
       " '',\n",
       " 'pretty accurate',\n",
       " '',\n",
       " 'astronomy',\n",
       " 'internal beta rollout tonight wider tomorrow',\n",
       " 'coming',\n",
       " 'materials science wo regret',\n",
       " 'major fed rate hike risks deflation',\n",
       " 'lmk happens',\n",
       " 'absolutely tesla fleet australia growing rapidly need ramp service general',\n",
       " 'tesla north america aiming hour service',\n",
       " '',\n",
       " 'anubis',\n",
       " 'nice dressing sink knocking random doors choice let sink',\n",
       " 'complex missions',\n",
       " 'bot block party',\n",
       " 'assuming efficient pv cells surface coverage',\n",
       " 'exactly ecosystem entirely dependent sun \\n\\n civilization energy needs absurdly tiny compared sun sends free gwh day',\n",
       " 'reason static fires better break things ground en route orbit',\n",
       " 'solar panels ground mount rooftop paired stationary batteries civilization primary source energy sure day follows night \\n\\n mark words',\n",
       " 'love graffiti art giga berlin',\n",
       " 'land tiny percentage needed power entire country',\n",
       " 'looking far',\n",
       " '',\n",
       " 'promising conversations apple starlink connectivity iphone team obv super smart \\n\\n sure closing link space phone work best phone software hardware adapt space based signals vs starlink purely emulating cell tower',\n",
       " 'note putting lot time personally advancing tesla service hopefully starting felt tesla owners',\n",
       " 'right credit tesla owners $ change appointments hours notice reciprocal',\n",
       " 'lot people realize tesla makes uninterruptible power supplies home powerwall',\n",
       " 'remember',\n",
       " 'thread brings lot memories',\n",
       " 'improved',\n",
       " 'primary solution sustainable energy future solar wind batteries sun shine wind blow interconnected conventional high voltage lines unknown technology needed \\n\\n hydro+geothermal+fission non trivial contributors',\n",
       " 'fusion expensive energy given difficulty obtaining transporting source fuel plus maintaining reactor \\n\\n far better use sun thermonuclear reactor need refuel service',\n",
       " '',\n",
       " 'squares fog war tech tree different pieces random spawn chess simple game prefer polytopia',\n",
       " 'interesting',\n",
       " 'punny',\n",
       " 'solar + batteries needed batteries great dealing peak demand',\n",
       " '',\n",
       " 'accept cookies choc chip',\n",
       " 'twitter effort bot spam removal subpoenas problem place',\n",
       " '',\n",
       " 'advised potential witnesses provide cooperation court control actions',\n",
       " 'read actual ruling zero david sack response zero',\n",
       " 'claim criticism rings power means racist outing closet racists',\n",
       " 'peter jackson excellent work lord rings hobbit stretched long short book',\n",
       " 'supply low ordering powerwall possible end year',\n",
       " '',\n",
       " 'order tesla powerwall battery blackout protection',\n",
       " 'comments bots',\n",
       " 'male character far coward jerk galadriel brave smart nice',\n",
       " 'release probably end week needs bit polish',\n",
       " 'tolkien turning grave',\n",
       " 'relatively small number code changes practical effect significant',\n",
       " 'starlinks reach orbit',\n",
       " 'probably help proportionate cost raising children',\n",
       " 'important south korea currently tracking lose half population roughly generation long lifespan hides dire nature problem',\n",
       " 'invited open shows chris try flounder',\n",
       " 'important',\n",
       " 'accurate assessment raptor design started switched best combo high efficiency ease operation imo \\n\\n delta v difference small missions tank smaller insulation needed',\n",
       " 'moody irrelevant',\n",
       " '',\n",
       " 'hope connor',\n",
       " '',\n",
       " '',\n",
       " '$ /bot basis deal',\n",
       " 'sure sounds higher \\n ',\n",
       " 'intend soon possible',\n",
       " '',\n",
       " 'aiming flights year',\n",
       " 'launching days',\n",
       " 'goes owners week',\n",
       " 'sjm question',\n",
       " 'spent day walking entire giga berlin production line team excellent work',\n",
       " 'better reduced latency jitter hardware command loop time object detection brake actuation better',\n",
       " 'kickass internet connection coming royal caribbean ships soon',\n",
       " '',\n",
       " 'ancient times',\n",
       " 'grow meters time',\n",
       " 'days owners going major issues \\n\\n note hopefully going week wide release beta',\n",
       " 'ask',\n",
       " 'agreed recently change \\n\\n intense effort underway achieve robust engine containment case rud protect booster engines launch ring',\n",
       " 'happen matter time',\n",
       " 'godspeed artemis',\n",
       " '',\n",
       " 'swoop x meant represent rocket arc orbit',\n",
       " 'hopefully week',\n",
       " 'somewhat agonized tesla spacex font design love fonts tbh similarities particularly use negative space little tweaks years',\n",
       " 'wise actions',\n",
       " 'diet coke amazing',\n",
       " 'share things thread working life find helpful',\n",
       " 'lift little',\n",
       " 'lbs unhealthy peak weight',\n",
       " 'time time share things working case find helpful',\n",
       " 'zero fasting app',\n",
       " 'advice friend fasting periodically feel healthier',\n",
       " 'lot place',\n",
       " 'gnus news snooze',\n",
       " 'coming',\n",
       " 'ares',\n",
       " 'great dane eating small piece ham tiny village \\n\\n hamlet eating hamlet hamlet \\n\\n middle credit gam',\n",
       " 'squeezing extra performance falcon metric tons actual useful orbit booster fairing reusable',\n",
       " 'times new roman',\n",
       " 'getting orbit harder',\n",
       " 'caffeine troubling',\n",
       " 'sadly anti human',\n",
       " 'countries increasing nuclear power generation insane national security standpoint bad environment shut',\n",
       " 'lotr g',\n",
       " 'safe output exceed mass known universe',\n",
       " 'similarly high cycle life nickel cathode possible optimizing \\n\\n adding silicon primarily carbon anode improves energy density reduces cycle life large volumetric changes charge discharge',\n",
       " '',\n",
       " 'plus pessimism future false overpopulation fears',\n",
       " '',\n",
       " 'think global warming major risk',\n",
       " '',\n",
       " 'mark words',\n",
       " 'population collapse low birth rates bigger risk civilization global warming',\n",
       " 'summary',\n",
       " '',\n",
       " '',\n",
       " 'note connectivity mbits cell zone work great texting voice calls high bandwidth',\n",
       " 'starlink launching year transmit direct mobile phones eliminating dead zones worldwide',\n",
       " 'livestream big news hour',\n",
       " 'releases monday night week later wide beta version',\n",
       " 'ron barron',\n",
       " 'crazy',\n",
       " 'gladly obey commands tell saying',\n",
       " 'doubt criticism public private welcome wide beta \\n\\n early beta known issues reason release limited number cars discover unknown issues',\n",
       " 'let clear james contacted directly included early beta cars employees \\n\\n early beta explicitly issues rolled widely publicly criticizing asked wrong',\n",
       " 'special',\n",
       " 'course civilization upward',\n",
       " '',\n",
       " 'mechazilla loads starship launchpad',\n",
       " '',\n",
       " '',\n",
       " 'limited release reason ask included early beta releases complain',\n",
       " '',\n",
       " 'spam prevalence shared board board chose disclose public',\n",
       " '',\n",
       " 'important thread',\n",
       " 'case feels buying fine whistle',\n",
       " 'verified',\n",
       " '',\n",
       " '',\n",
       " 'waking morning',\n",
       " '',\n",
       " 'neuralink progress update tell october st halloween',\n",
       " 'main goals year \\n\\n starship orbit \\n fsd wide release \\n\\n things course giant kahunas require insane work super talented people \\n\\n honor work human beings',\n",
       " 'fastest way downtown known physics standard model proving quiet resilient',\n",
       " 'simplified hyperloop demo tunnel austin san antonio',\n",
       " 'tunnels active use vegas try town expanding connect major destinations vegas plus airport',\n",
       " '',\n",
       " 'funny simultaneous reactions saying impossible years ago',\n",
       " '',\n",
       " 'glad working giving tough case solve field testing \\n\\n early version extra cautious waits moderately big gap traffic cross upcoming releases better heavy traffic',\n",
       " 'wanted emphasize tesla software ai team deserves credit talent level tesla incredible',\n",
       " 'note upgrade existing car fsd mins tesla app',\n",
       " 'wide release fsd beta price fsd rise $ north america september \\n\\n current price honored orders sept delivered later',\n",
       " 'fsd beta started rolling tesla owners night build big step forward \\n\\n probably end week wider release \\n\\n weeks provide fsd beta participants',\n",
       " 'tesla autopilot ai team great work point releases needed polish shine',\n",
       " '',\n",
       " 'worth hearing tesla autopilot software ai progress',\n",
       " 'mentioned previously major release need cautious goes beta participants later today',\n",
       " '',\n",
       " '',\n",
       " 'need new po box tweeting',\n",
       " 'nice letter bill nix prof stanford grad studies permanent deferment',\n",
       " 'fairing half fully capable reentry vehicle thrusters thermal protection avionics sensor suite',\n",
       " 'free willy free',\n",
       " 'grateful',\n",
       " 'major code changes extra cautious rollout \\n\\n releasing tesla owners week accommodate feedback release customers week release rest fsd beta',\n",
       " 'entropy',\n",
       " '',\n",
       " 'questions twitter possible avoid answering',\n",
       " 'modifying car delivery legal america',\n",
       " 'said add autoconfigure mirrors',\n",
       " 'mirrors cause range reduction highway speed',\n",
       " 'mirrors wo needed self driving future',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'reason agree guy',\n",
       " '',\n",
       " 'magic moment',\n",
       " 'shall',\n",
       " 'seek mars bars tomorrow',\n",
       " 'mom important career',\n",
       " 'highly recommend',\n",
       " '',\n",
       " 'mercury forbidden candy',\n",
       " '',\n",
       " '',\n",
       " 'earth energy comes sun dark iceball near absolute zero sun essentially entire ecosystem solar powered \\n\\n civilization uses tiny energy comparison hard generate wind solar',\n",
       " 'team man u. fav team kid',\n",
       " 'u',\n",
       " 'standup hustle',\n",
       " 'buying coca cola cocaine despite extreme popularity',\n",
       " 'long running joke twitter buying sports teams',\n",
       " 'got build youtube subscriptions',\n",
       " '',\n",
       " 'note trying reduce delivery times quickly possible long wait times thing',\n",
       " 'mean',\n",
       " 'buying manchester united ur welcome',\n",
       " 'downside elf ear surgery probably outweighs upside',\n",
       " 'clear support left half republican party right half democratic party',\n",
       " 'reasonably accurate translation',\n",
       " 'turn',\n",
       " 'tesla autopilot ai team amazing work worth',\n",
       " 'strange receives little attention media',\n",
       " 'border crossing year',\n",
       " 'congrats giga shanghai making millionth car total teslas m.',\n",
       " 'production bigger challenge demand',\n",
       " 'hope self sustaining city mars years',\n",
       " 'read instructions',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'ahem',\n",
       " 'pretty wild car company powerful supercomputer earth',\n",
       " 'phase dojo wo need buy incremental gpus year',\n",
       " 'waitlist long enable ramp production',\n",
       " 'adding inner engines',\n",
       " 'yikes',\n",
       " '',\n",
       " 'orbital plane polar satellites',\n",
       " 'coincidences',\n",
       " '',\n",
       " 'sticky situation',\n",
       " 'run humanity long way equal time earth',\n",
       " 'mars day',\n",
       " 'u seen sex tape',\n",
       " 'attempt long duration engine firing test autogenous pressurization',\n",
       " 'starship static fire',\n",
       " 'audited year default',\n",
       " 'think approved language days height challenged sellers',\n",
       " 'fate irony',\n",
       " 'deep thot',\n",
       " '',\n",
       " '',\n",
       " 'cgi irl',\n",
       " 'payola',\n",
       " '',\n",
       " 'tesla advertise car companies',\n",
       " 'real scam',\n",
       " 'guardian swallows scam video hook line sinker',\n",
       " 'years ago',\n",
       " 'coming soon scaling sustainable energy civilizational level enable bright future earth',\n",
       " 'tesla mile range semi truck starts shipping year cybertruck year',\n",
       " 'wrote years ago',\n",
       " '',\n",
       " '',\n",
       " 'day',\n",
       " '',\n",
       " '',\n",
       " '\\n\\n hopefully unlikely event twitter forces deal close equity partners come important avoid emergency sale tesla stock',\n",
       " 'tesla fremont team kicking',\n",
       " 'spacex falcon team',\n",
       " 'happens',\n",
       " '',\n",
       " 'growing requires insane work achievable outstanding execution',\n",
       " 'investment automation',\n",
       " 'high',\n",
       " 'release big',\n",
       " '',\n",
       " '',\n",
       " 'twitter spoken',\n",
       " 'fsd beta drops',\n",
       " '',\n",
       " '',\n",
       " 'saxon james musk',\n",
       " '',\n",
       " 'twitter daily users fake spam',\n",
       " 'challenge public debate twitter bot percentage \\n\\n let prove public twitter fake spam daily users',\n",
       " '',\n",
       " 'question',\n",
       " 'followers',\n",
       " 'summary problem \\n\\n twitter simply provides method sampling accounts confirmed real deal proceed original terms \\n\\n turns sec filings materially false',\n",
       " 'love smell hydraulic fluid morning',\n",
       " 'launch pad',\n",
       " 'moving rocket launch pad',\n",
       " 'hustling starship booster pad test outer ring engines',\n",
       " 'send podcast',\n",
       " 'thank goodness senator manchin',\n",
       " 'kids cars',\n",
       " 'stone destiny',\n",
       " 'fun hang',\n",
       " 'whiskey',\n",
       " '',\n",
       " 'pretty',\n",
       " '',\n",
       " 'tesla mins austin international airport silly build private airport existing commercial airport needs runway austin growing fast',\n",
       " '',\n",
       " 'ratio digital biological compute growing fast worth tracking',\n",
       " 'successful orbital flight probably months',\n",
       " 'x',\n",
       " '',\n",
       " 'came pretty cnbc piece spacex starship',\n",
       " 'estimate high point valid',\n",
       " 'worth reading close match philosophy',\n",
       " 'time vote',\n",
       " '',\n",
       " 'x doges',\n",
       " 'water bridge',\n",
       " '',\n",
       " '',\n",
       " 'twitter',\n",
       " 'sure hard find news source accurate relevant totally depressing \\n\\n old school version economist jon stewart daily colbert report great',\n",
       " '',\n",
       " 'floki pic tomorrow',\n",
       " 'media strong negative bias driven clicks help \\n\\n unfortunately generate lots clicks \\n\\n things cycles \\n\\n starts boring readers knock build \\n\\n cycle happened times',\n",
       " '',\n",
       " 'thanksgiving year watching episodes vikings',\n",
       " '',\n",
       " '',\n",
       " 'reality actually alien soap opera ratings',\n",
       " '',\n",
       " 'free people jail weed',\n",
       " 'thread',\n",
       " '',\n",
       " 'sigh',\n",
       " 'races set harley quinn',\n",
       " '',\n",
       " 'live interesting times',\n",
       " 'people nonsense personally little nonsense',\n",
       " '',\n",
       " 'tesla + twitter -&gt twizzler',\n",
       " 'interaction twitter accounts lower recent weeks days accurate',\n",
       " 'saxon',\n",
       " 'based',\n",
       " 'friend years ago',\n",
       " 'try voice command open butthole tesla',\n",
       " '',\n",
       " '',\n",
       " 'great style',\n",
       " 'point time hybrid cars phase',\n",
       " 'heatwave shortville',\n",
       " 'probably week away people outside california notice improvements',\n",
       " 'working super hard ready',\n",
       " 'wikipedia losing objectivity',\n",
       " 'sure starship reach escape velocity hubris certainly',\n",
       " 'thank farmers',\n",
       " 'products bring joy rare',\n",
       " 'early sure',\n",
       " 'unwise risk',\n",
       " 'tesla commodity prices trending fwiw',\n",
       " 'inflation trending',\n",
       " 'support years',\n",
       " 'harder friends enemies skill improving',\n",
       " 'sub lightspeed needed interstellar intergalactic tough',\n",
       " 'media click seeking machine dressed truth seeking machine',\n",
       " 'compatible existing religions surely god want creation',\n",
       " 'new philosophy future needed believe curiosity universe expand humanity multiplanet interstellar species',\n",
       " 'new philosophy future needed',\n",
       " 'talked sergey yesterday says knows talked wsj',\n",
       " 'public person standard win defamation lawsuit news org impossible satan source psychic \\n\\n nicole public person win hope sues fake hit pieces',\n",
       " 'seriously',\n",
       " 'business insider trading real publication',\n",
       " 'years ago',\n",
       " 'nice',\n",
       " 'exactly',\n",
       " 'weirdly publications print millions paper copies day',\n",
       " 'journalism reading story internet changing little pressing send',\n",
       " 'sickonolfi zero journalistic integrity \\n',\n",
       " 'jeff',\n",
       " 'bon voyage',\n",
       " 'sickonolfi pack attack chihuahuas burning phone lines today revenge bogus article',\n",
       " '',\n",
       " 'exactly',\n",
       " 'point',\n",
       " 'attention gone supernova super sucks unfortunately trivial articles generate lot clicks \\n\\n try best heads focused useful things civilization',\n",
       " 'media click maximizing machine story involving gets lot clicks',\n",
       " 'teslas come free karaoke app',\n",
       " 'das baby hit',\n",
       " 'media click seeking machine dressed truth seeking machine',\n",
       " '',\n",
       " 'sure way',\n",
       " 'real problem zero journalistic integrity',\n",
       " 'picture worth tweets',\n",
       " 'sergey yesterday afternoon',\n",
       " 'single piece casting reduces weight greatly simplifies factory increases ride quality reduces road noise',\n",
       " 'article',\n",
       " 'video games enjoyed past year',\n",
       " 'evidence simulation',\n",
       " '',\n",
       " 'movie idea boss baby meets das boot \\n das baby hijinks high seas',\n",
       " 'lmaooo absolutely',\n",
       " 'nope',\n",
       " 'guess wsj supposed high standard journalism right way sub tabloid \\n\\n wsj running stories actually matter readers solid factual basis party random hearsay',\n",
       " 'wsj run bs hit pieces tesla lost count embarrassing frankly \\n\\n wrote article saying fbi arrest called fbi ask said wsj article total bs \\n\\n shortseller fud',\n",
       " 'sex ages sigh',\n",
       " 'character assassination attacks reached new level year articles burgers \\n\\n work crazy hours time shenanigans \\n\\n key people involved alleged wrongdoings interviewed',\n",
       " 'total bs sergey friends party night \\n\\n seen nicole twice years times people romantic',\n",
       " 'ironic disney disparage entire class rodents main character rodent jealous',\n",
       " 'dark origin lemming mass suicide myth \\n',\n",
       " '',\n",
       " 'self driving electric cars matters \\n\\n gas car autonomy riding horse flip phone happens niche',\n",
       " 'software key future',\n",
       " 'ferdinand kids',\n",
       " 'falcon rising fog',\n",
       " 'falcon moon',\n",
       " 'sjm m',\n",
       " '',\n",
       " 'schadenfreude oder schatzifreude',\n",
       " 'schatzenfreude',\n",
       " 'great thread',\n",
       " 'gehalt und gestalt',\n",
       " 'deep history memes rock',\n",
       " '',\n",
       " 'major improvement respect complex left turns',\n",
       " 'end week team working hard',\n",
       " '',\n",
       " 'odd',\n",
       " 'service turns month time required deliver user terminal order',\n",
       " 'excited work tesla service enable hour service possible applying formula pit crew techniques teslas',\n",
       " 'major volcanic eruptions underappreciated civilizational risks',\n",
       " 'tough times',\n",
       " 'starlink available countries \\n',\n",
       " 'congrats spacex team record number launches',\n",
       " 'optimus primed',\n",
       " '',\n",
       " 'rubber glue',\n",
       " '',\n",
       " 'interesting smart china expendable rockets future',\n",
       " 'congrats incredible company airbnb book',\n",
       " '',\n",
       " 'tbh motivation work eat healthier shirt outside year',\n",
       " '',\n",
       " 'years ago',\n",
       " 'upgrades',\n",
       " '',\n",
       " '',\n",
       " 'sounds bad',\n",
       " '',\n",
       " 'real life \\n fantasy \\n caught landside \\n escape reality',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'earth basically humans',\n",
       " 'exactly',\n",
       " 'best features model x',\n",
       " 'teslas usa vehicles',\n",
       " 'total scam',\n",
       " 'calves bigger tho',\n",
       " 'think fremont derelict building giga nevada rocks bushes started \\n\\n california dozen car factories nummi close tesla fremont biggest car factory north america',\n",
       " 'congrats tesla fremont + giga nevada making millionth car',\n",
       " 'vote shares tesla',\n",
       " '',\n",
       " 'start times mass orbit year needed life multiplanetary',\n",
       " '',\n",
       " 'damn shirt free nip \\n factory btw',\n",
       " 'needs tweaks',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'classic',\n",
       " 'remember means definitely spring chicken',\n",
       " 'arguably know death taxes certainty bf',\n",
       " 'worth getting particle counter',\n",
       " 'future product list especially important places austin level amounts pollen air',\n",
       " 'things wild andromeda collides galaxy',\n",
       " 'running',\n",
       " 'monitor desk beeps',\n",
       " 'twice useful mass orbit rest earth combined',\n",
       " 'absolutely',\n",
       " 'accurate word propellant fuel starship liquid oxygen fuel \\n\\n propellant cost primary importance fully reusable rocket reusable rockets want high thrust thrust t w irrelevant',\n",
       " 'use example lot',\n",
       " 'starlink bandwidth varies lot depending user terminal density time day long wait areas \\n\\n throughput roughly linear total satellites operation satellites times better conservative estimate',\n",
       " 'starlink gamechanger remote locations',\n",
       " '',\n",
       " 'global',\n",
       " 'cumulative tonnage orbit year right metric',\n",
       " '',\n",
       " 'write great',\n",
       " 'charlie ergen trying steal band meant space internet',\n",
       " 'progress',\n",
       " 'making progress steam integration demo probably month',\n",
       " 'flat trade',\n",
       " '',\n",
       " 'autonomous rocket landing autonomous ship',\n",
       " 'actually suggested team need pointy based movie joke likes pointy kept way',\n",
       " 'bagels',\n",
       " 'inflation calms lower prices cars',\n",
       " 'tesla protect life earth \\n spacex extend life',\n",
       " 'years human landing launch rate growth exponential \\n\\n assumes transferring rendezvous m total people needed',\n",
       " 'mars fixer upper planet great potential',\n",
       " 'mars admittedly fixer upper planet',\n",
       " 'scale visit',\n",
       " '',\n",
       " 'wonder species magellanic clouds wondering lives big galaxy orbit',\n",
       " 'small tubes wiring need nested bigger tube thermal protection kinda conduit house \\n\\n engines booster base extremely robust high strength stainless steel bulletproof handgun mm thickness booster dome mm',\n",
       " 'electric power booster ship needed engines running incremental power draw tvc bad local supercaps engine deal power spikes',\n",
       " 'enabling engines heat shrouds save tons things considered \\n\\n shrouds risk fuel leaks contained shroud forming mox bomb \\n\\n booster purging engine shrouds flight prevent',\n",
       " 'mass necessitated engine design count engine mass eg shrouds tvc hydraulic power excess purge gas \\n\\n raptors production electric tvc saving ton hydraulics mass booster',\n",
       " 'dragon launching mins',\n",
       " 'importantly need delete thermally protect remaining secondary structure remove shrouds',\n",
       " 'goes internal beta tomorrow external week handle chuck complex left turn \\n\\n beta hopefully end month amounts incorporating highway importance reduced releases',\n",
       " '= bs',\n",
       " 'tesla honor working',\n",
       " 'wow',\n",
       " '',\n",
       " '',\n",
       " 'absolutely \\n\\n lithium batteries new oil',\n",
       " 'testing goes soon month',\n",
       " '',\n",
       " 'gives new meaning pros',\n",
       " 'imagine msnbc',\n",
       " '',\n",
       " 'a+ cinematography',\n",
       " 'ancient times',\n",
       " 'booster propulsion section damage appears minor need inspect engines best high bay',\n",
       " 'starship launch site tonight',\n",
       " 'join underground movement',\n",
       " 'excited potential',\n",
       " '',\n",
       " 'lmaooo',\n",
       " 'oh irony lol',\n",
       " 'problem recycle pack think battery pack super high grade ore better start high grade ore low grade',\n",
       " 'fifth element great',\n",
       " 'base vehicle flashlight hour ago shut pad night safety know morning',\n",
       " 'congrats \\n\\n simulators spend money rendering',\n",
       " 'rereading life greece durant recent months read american caesar masters doom engineer wages destruction storm steel \\n\\n book fiction lately video games better stories days',\n",
       " '',\n",
       " 'recommend lot books',\n",
       " 'little red green led indicators',\n",
       " 'youtube keeps playing annoying scam ads time use algorithm convinced money audible',\n",
       " '',\n",
       " 'things going forward \\n\\n particular issue specific engine spin start test raptor complex start sequence \\n\\n going forward wo spin start test engines',\n",
       " '',\n",
       " 'trump end term old chief executive let united states america \\n\\n desantis runs biden desantis easily win need campaign',\n",
       " 'drama want bull china shop situation single day \\n\\n think legal maximum age start presidential term',\n",
       " 'hate man time trump hang hat sail sunset \\n\\n dems attack trump way survive regain presidency',\n",
       " 'tesla automatic cabin overheat protection real difference record heatwaves \\n\\n ability adjust activation temperature coming software release',\n",
       " '',\n",
       " 'cryogenic fuel added challenge evaporates create fuel air explosion risk partially oxygen atmosphere earth \\n\\n said lot sensors detect later',\n",
       " 'actually team assessing damage',\n",
       " '',\n",
       " '',\n",
       " '+',\n",
       " 'mimic + dark moon + stars ruin',\n",
       " '',\n",
       " '',\n",
       " 'absolutely',\n",
       " 'problematic',\n",
       " 'chance experiencing mild acid reflux night affecting quality sleep consciousness awareness',\n",
       " 'children essential future',\n",
       " 'improved quality sleep raise head bed cm eat hours bedtime',\n",
       " 'polar launches enable complete coverage earth approved local government',\n",
       " 'chuckmate',\n",
       " '',\n",
       " 'hello',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'future wars drones human crews planes tanks chance \\n\\n exception purely analog human controlled vehicle far resilient emf weapons',\n",
       " 'controls teleprompter real president',\n",
       " 'know little today want know meaning life right question ask douglas adams \\n\\n wait guys related',\n",
       " 'sponges starfish obv',\n",
       " 'consciousness understand nature universe clams',\n",
       " 'interesting bot attack',\n",
       " 'kids worth possible planning increase childcare benefits companies significantly \\n\\n hopefully companies \\n\\n musk foundation plans donate directly families \\n\\n hopefully details announced month',\n",
       " 'agreed needs addressed',\n",
       " 'world gone mad',\n",
       " 'terrible news',\n",
       " 'great',\n",
       " 'real question',\n",
       " 'great experience tokyo osaka',\n",
       " 'china japan trains \\n\\n took bullet train beijing terracotta army',\n",
       " 'super fired future product development tesla team honor work',\n",
       " 'ruggedized relentless salt spray extreme winds storms deep ocean easy',\n",
       " 'dual high performance terminals important maintaining connection choppy seas heavy storms \\n\\n obv premium pricing way cheaper faster alternatives \\n\\n spacex paying $ month worse connection ships',\n",
       " 'flying electric boat sickkk',\n",
       " 'starlink boats',\n",
       " 'bad \\n\\n high time future looked future \\n\\n goes fashion',\n",
       " 'pretty van roof height stand sit shade',\n",
       " 'optional solar power canopy extends sides van tripling roof area',\n",
       " '',\n",
       " 'exactly',\n",
       " 'tesla highly configurable robovan people cargo',\n",
       " 'far people illusion earth overpopulated birth rate trends obviously headed population collapse',\n",
       " 'hope big families congrats',\n",
       " 'population mars zero people',\n",
       " 'mark words sadly',\n",
       " 'best help underpopulation crisis \\n\\n collapsing birth rate biggest danger civilization faces far',\n",
       " 'wait minute doc telling built time machine delorean future',\n",
       " '',\n",
       " 'highly recommend revolutions mike duncan especially season',\n",
       " 'world actually vastly better orwell imagined vastly surveillance',\n",
       " 'troubling',\n",
       " 'supporting doge possible',\n",
       " 'moon brought \\n mars future',\n",
       " 'common goal \\n humanity fight',\n",
       " 'exactly',\n",
       " 'pressures government placed twitter',\n",
       " 'humanity reach mars lifetime',\n",
       " 'flatulence earther',\n",
       " '',\n",
       " 'later year',\n",
       " '',\n",
       " 'zip vegas super fast teslas tunnels',\n",
       " 'structural pack right overall architecture physics standpoint far optimized',\n",
       " 'find gold toe sock inevitably kilter washed little troubling esthetically arguably bit corpo',\n",
       " 'sock con conference socks',\n",
       " 'new magazine cover articles practically write',\n",
       " 'veritable sock aficionado',\n",
       " 'guy gets',\n",
       " 'sock tech advanced pretty sock form days',\n",
       " 'confess penchant creative socks',\n",
       " 'time',\n",
       " 'success fact super fun parties spoke wrote incredibly',\n",
       " 'bleak posts generate clicks happier moments history nice',\n",
       " 'actual matrix math ai compute power overwhelmingly dot products',\n",
       " 'going way far squashing dissenting opinions',\n",
       " 'pro nuclear chart overly weighted significantly overstates mining required solar big grain salt',\n",
       " 'oil burned',\n",
       " 'knew',\n",
       " '',\n",
       " 'elvis elvish h',\n",
       " 'happy july',\n",
       " '',\n",
       " 'great work',\n",
       " 'suit tragic',\n",
       " 'talulah designed dress birthday party party genius',\n",
       " 'honored meet yesterday',\n",
       " 'venice site great remembrance',\n",
       " 'feeling little bored',\n",
       " 'wise words sjm',\n",
       " 'attempt bait switch satellite spectrum cellular spectrum super shady unethical \\n\\n successful hurt served completely unserved world messed',\n",
       " 'hardly knows',\n",
       " 'probably months',\n",
       " 'twitter real life different',\n",
       " 'vote confidence appreciated',\n",
       " '',\n",
       " 'artificial insemination',\n",
       " 'ai gets better day',\n",
       " 'great suggestions comments',\n",
       " 'stock \\n',\n",
       " 'largest wheel cheese beverly hills cheese shop',\n",
       " 'love cheeses hard particular best stilton',\n",
       " 'sheer variety cheese amazing',\n",
       " 'favorite cheese',\n",
       " 'cgi irl',\n",
       " 'trending emptiness',\n",
       " 'contributor',\n",
       " 'super talented team spacex',\n",
       " 'interesting',\n",
       " 'computer',\n",
       " '',\n",
       " '',\n",
       " 'supporting dogecoin',\n",
       " 'shadow crew',\n",
       " 'feel swindled time drink',\n",
       " 'gwynne best',\n",
       " 'teach lot engineering physics growing environment austere bleak',\n",
       " 'love kids',\n",
       " '',\n",
       " 'eventually runs time \\n',\n",
       " 'happy father day',\n",
       " 'smell wifi know real',\n",
       " 'congrats spacex falcon team executing flawless launches days',\n",
       " 'question',\n",
       " 'answer question twitter',\n",
       " 'encourage people change',\n",
       " 'pretty sure unique',\n",
       " 'changing starlink default wifi stinky',\n",
       " '\\n writers \\n\\n past \\n present \\n future',\n",
       " 'thing keeping orbital rocket programs alive government protection deader doornail knows \\n\\n oh comme ci comme',\n",
       " 'super weird thing falcon orbital booster land refly years',\n",
       " 't',\n",
       " 'feels vu',\n",
       " 'thrust mass focus heavily production rate reliability \\n\\n mass thrust isp improve production rate reliability cost \\n\\n way life multi planetary extend consciousness void',\n",
       " '',\n",
       " 'currency',\n",
       " 'tesla spacex merch road',\n",
       " 'rock',\n",
       " 'humans',\n",
       " '',\n",
       " 'congratulations giga berlin team making cars week',\n",
       " '',\n",
       " 'couple months looks place mark live',\n",
       " 'dirty rocket',\n",
       " 'documentary coming',\n",
       " 'watch opening scene idiocracy \\n\\n ask friends having kids sounds exactly movie \\n\\n',\n",
       " 'son sjm wanted know cats reconsider',\n",
       " 'social media general',\n",
       " 'hmm',\n",
       " 'tiktok destroying civilization people think',\n",
       " 'interesting',\n",
       " 'lame',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'free advertising',\n",
       " 'hyundai pretty',\n",
       " 'exactly',\n",
       " 'rocket landings triple digits',\n",
       " 'best landing video date starlink',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'thread',\n",
       " 'dragon shields',\n",
       " 'probably launch countdowns pass abort triggers hopefully countdown month',\n",
       " 'achievable',\n",
       " '',\n",
       " 'accurate',\n",
       " 'exactly',\n",
       " 'wow',\n",
       " '',\n",
       " 'interesting',\n",
       " '',\n",
       " 'spacex team making great progress cape starbase',\n",
       " 'exactly',\n",
       " '',\n",
       " 'sigh',\n",
       " 'sink band let tiny sink',\n",
       " '',\n",
       " 'goes',\n",
       " 'thread',\n",
       " 'awe busted',\n",
       " 'austin airport needs upgraded fast possible',\n",
       " 'kids',\n",
       " '',\n",
       " '',\n",
       " 'bigger risk ai trends continue humanity cease exist',\n",
       " '',\n",
       " '',\n",
       " 'better',\n",
       " 'civilization sterilized',\n",
       " 'amazing flying scenes expected writing',\n",
       " '',\n",
       " 'love fred astaire',\n",
       " 'second',\n",
       " 'absolute best humility',\n",
       " 'point wear monocle hat',\n",
       " '',\n",
       " 'sink',\n",
       " 'dressing sink halloween choice let',\n",
       " 'correct',\n",
       " 'original gun great movie rewatched looking forward seeing sequel',\n",
       " 'far entire history human civilization flash pan potential longer',\n",
       " 'crazy model content car today',\n",
       " 'buyers competing electric cars receive $ tax credit tesla',\n",
       " '',\n",
       " 'gave away',\n",
       " 'supported yang time desantis better chance winning',\n",
       " 'thinking creating super moderate super pac supports candidates centrist views parties',\n",
       " '',\n",
       " 'desantis',\n",
       " 'tbd',\n",
       " 'voted mayra flores time voted republican \\n\\n massive red wave',\n",
       " '',\n",
       " '',\n",
       " 'engine moving steer',\n",
       " 'fr cap',\n",
       " 'starship high bay',\n",
       " 'driving alpha version fsd highway ready probably ready wide release summer',\n",
       " 'cryptonight',\n",
       " '',\n",
       " 'probably later year',\n",
       " 'obviously tried tesla fsd',\n",
       " 'cut opex cogs dramatically chance happened',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'exactly',\n",
       " 'highly unusual btw statistically richer fewer kids',\n",
       " 'reusability matters far size',\n",
       " 'second starship stack ready fly august monthly',\n",
       " 'starship ready fly month high bay mega bay late night reviewing progress',\n",
       " 'tesla tech tree insane',\n",
       " '',\n",
       " 'build moats build tech trees',\n",
       " 'told ocelot seen boca chica area years \\n\\n motion activated cameras starbase thousands clips coyotes dogs cats ocelots',\n",
       " 'time rocket capable establishing permanent bases moon mars',\n",
       " 'exactly',\n",
       " '',\n",
       " '',\n",
       " 'mean',\n",
       " 'weeks',\n",
       " 'past years demographic disaster',\n",
       " 'case love',\n",
       " 'platform considered inclusive fair biased half country',\n",
       " '',\n",
       " 'progress',\n",
       " '',\n",
       " 'nice',\n",
       " 'working accelerating rhd model y production expect demand high',\n",
       " '',\n",
       " '',\n",
       " 'words beautiful',\n",
       " 'exactly',\n",
       " '',\n",
       " 'experts read wiki citations',\n",
       " '',\n",
       " 'merlin simple compared raptor',\n",
       " 'starlink comes',\n",
       " '',\n",
       " 'weird wonder happening',\n",
       " 'pretty great',\n",
       " 'james',\n",
       " 'son saxon suggested having party world world party day',\n",
       " 'wen humor',\n",
       " 'rivalry strong',\n",
       " 'let try',\n",
       " 'austin weirder',\n",
       " 'crucified',\n",
       " 'bug',\n",
       " '',\n",
       " '',\n",
       " 'think kinda funny',\n",
       " 'better world judgy',\n",
       " 'humor great joys life',\n",
       " 'congratulations new book',\n",
       " 'simultaneously told gender differences exist genders profoundly different irreversible surgery option \\n\\n wiser explain dichotomy',\n",
       " '',\n",
       " '',\n",
       " 'tons force achievable',\n",
       " 'lister ridiculed establishment right question accepted wisdom bow weight evidence',\n",
       " 'mars colonial transporter',\n",
       " 'raptor rocket engines producing metric tons force',\n",
       " '',\n",
       " '',\n",
       " 'bay area saturated user terminals wait time terminal long \\n\\n rush hour speeds improve satellites reach operational orbits giant improvement sats \\n\\n note speeds outside rush hour times high',\n",
       " 'best outcome route packets starlink user terminal ground station roof server center \\n\\n touch regular internet',\n",
       " '',\n",
       " 'probability injury according government \\n ',\n",
       " 'exactly',\n",
       " '',\n",
       " 'starlink inter satellite laser links operational end year dramatically reduce global latency \\n\\n light travels faster vacuum air fiber optic cables satellite path length shorter cables follow coastlines',\n",
       " 'possible sue law firms pursuing insane damages claims',\n",
       " 'karate kid bigger',\n",
       " 'crazy damages claims big car insurance costs',\n",
       " 'multiplayer gaming works pretty starlink eg league problem',\n",
       " 'civilization solar powered future',\n",
       " 'play video games want',\n",
       " '',\n",
       " 'gasoline fights fun tho',\n",
       " 'weeks',\n",
       " 'psychedelics mdma real difference mental health especially extreme depression ptsd seriously',\n",
       " 'times',\n",
       " 'gas station lighting brutal',\n",
       " 'pricey',\n",
       " 'real talk',\n",
       " '',\n",
       " 'noooo',\n",
       " '',\n",
       " 'going deep roundabouts noticeably better',\n",
       " 'heard gun check',\n",
       " 'special enjoying movies theater total strangers hope goes away',\n",
       " 'doctor strange multiverse madness',\n",
       " 'care lowers life expectancy',\n",
       " 'diet coke amazing especially soda fountain version movie theaters salt butter popcorn',\n",
       " '',\n",
       " 'average length tweet minus headers bytes text gb fit usb stick',\n",
       " 'twitter',\n",
       " 'glad',\n",
       " 'diabolical plan coming',\n",
       " 'little red riding hood psychedelics story makes ton sense',\n",
       " 'look adjust general recommend recirc range advantage small',\n",
       " 'odd mistake talking wolf grandmother sort octave range wolf',\n",
       " '',\n",
       " 'think saw elden ring',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'exactly companies tesla solar powerwall stop',\n",
       " 'youtube nonstop scam ads',\n",
       " 'looks future',\n",
       " 'cgi irl',\n",
       " 'best product imo',\n",
       " 'resolution life sjm',\n",
       " 'correct',\n",
       " 'great journalists wapo trend super bad',\n",
       " '',\n",
       " 'people think china child policy \\n\\n china lowest birthdate year despite having child policy \\n\\n current birth rates china lose people generation \\n\\n population collapse',\n",
       " 'romeo juliet',\n",
       " '',\n",
       " 'chess released video game',\n",
       " 'dapper fellow',\n",
       " 'acid test competing socioeconomic systems needs build wall people escaping bad',\n",
       " 'realized common environmentalists annoyingly wrong \\n\\n conservationists conservationists potential time cosmic endowment \\n\\n friend',\n",
       " 'crazy rules extremely difficult build new california',\n",
       " 'shakespeare tempest prefer literally vs ironically',\n",
       " \"o wonder \\n goodly creatures \\n beauteous mankind o brave new world \\n people in't\",\n",
       " 'earth sustain times current human population ecosystem fine definitely people',\n",
       " 'sounds promising',\n",
       " 'brain vat vat skull senses memories electrical signals',\n",
       " 'hate humanity love humanity',\n",
       " 'build + starships transport life mars basically modern noah arks',\n",
       " 'actual starship model dispenses pez merch store',\n",
       " 'making life multiplanetary expands scope scale consciousness \\n\\n enables backup biosphere protecting life know calamity earth \\n\\n humanity life steward species transport life mars let',\n",
       " 'deck spacex hands update talk gave week',\n",
       " 'possible',\n",
       " 'expand scope scale consciousness learn answers questions',\n",
       " 'accurate',\n",
       " 'perfect better',\n",
       " 'solve left turn time',\n",
       " 'car navigate pin location complex surface parking lot hotel entrance \\n\\n covered underground parking lots car navigate inertial measurement wheel movement vision gps signal longer available',\n",
       " 'remarkable noted big differences humans mice cure mouse cancer cures work humans',\n",
       " 'close point offering eu regulators review makes sense',\n",
       " 'fsd beta expanding cars \\n\\n smooths intersection control especially long lefts starts handle roads map data \\n\\n point big deal months fsd able drive gps point zero map data',\n",
       " 'working tesla north american service \\n\\n goal cars receive day service wait',\n",
       " 'bts music videos',\n",
       " 'total headcount increase salaried fairly flat',\n",
       " '',\n",
       " 'think list enemies short',\n",
       " 'interesting',\n",
       " 'ah maxwell photobombing oscars party invited \\n\\n people push photo prominent people actually went island dozen times strange',\n",
       " 'saying far left taunt',\n",
       " 'thing remarkable doj leaking list media cares odd',\n",
       " '',\n",
       " 'falcon heavy flights later year incredible team spacex',\n",
       " 'sigh',\n",
       " 'wow',\n",
       " '',\n",
       " 'options default explicitly asked users time time',\n",
       " 'interesting',\n",
       " 'fallout nv great',\n",
       " 'usually sense humor apart mocking',\n",
       " 'announce hear simultaneous criticism impossible',\n",
       " 'far left far right lot hate \\n\\n simply replace word far loathing emotion lot people moderates',\n",
       " '',\n",
       " 'bro dinner el camino jack box night late people died food poisoning years earlier prices low',\n",
       " 'quality commenters',\n",
       " 'getty watermark coup de',\n",
       " 'diabolical',\n",
       " 'press plays class action law firms real plaintiffs puppets find masquerade',\n",
       " '',\n",
       " 'sigh',\n",
       " 'wow',\n",
       " '',\n",
       " 'johnny rotten sex pistols',\n",
       " '',\n",
       " 'trend',\n",
       " 'nice work openai hard useful things',\n",
       " 'interview',\n",
       " 'mr president \\n',\n",
       " 'primary purpose',\n",
       " 'currently age receive maximum social security benefits words govt concludes hold job',\n",
       " '',\n",
       " 'open primaries sound way candidates centrist \\n\\n term limits help gerontocracy problem frankly max age run min ages house senate president',\n",
       " 'advancing electric vehicles',\n",
       " '',\n",
       " 'bob nails \\n\\n endorsing political candidate competent',\n",
       " 'rare endorse political candidates \\n\\n political leanings moderate fully republican democrat confident case americans \\n\\n executive competence super underrated politics care lot',\n",
       " 'los angeles fortunate rick caruso running mayor',\n",
       " 'tesla ai day epic',\n",
       " 'tesla ai day pushed sept optimus prototype working',\n",
       " 'cryogenic proof test passed',\n",
       " 'eats food uses restrooms etc executive chef ivory tower stuff \\n\\n workers vs management class system worker',\n",
       " 'transformers replacing c heuristics post processing vision nn giant bag points \\n\\n note hate bloated mess modern c++ love simple c know compile terms actual cpu operations',\n",
       " '',\n",
       " 'set tweets illustrate recessions serve vital economic cleansing function',\n",
       " 'wanted ceo wanted work product technology bill harris sounded great ceo given intuit experience \\n\\n running companies hurts heart way bring technology design fruition',\n",
       " '',\n",
       " 'similar thing happened x paypal march',\n",
       " 'gpts run natively tesla trip chip vs needing round trip igpu',\n",
       " 'said',\n",
       " 'trying accelerate sustainable energy matters contribute goal \\n\\n personal choices respected',\n",
       " 'tesla scores year row lgbtq equality \\n ',\n",
       " 'donate centrist candidates parties',\n",
       " 'reference open primaries think idea \\n\\n favor result centrist candidates elected',\n",
       " 'amazing having orbital rocket fully rapidly reusable payload \\n\\n gave realized fully reusable \\n\\n long way',\n",
       " 'specs wikipedia right close \\n\\n thrust liftoff mass length payload grow time',\n",
       " 'encounter unexpected issues solid far extremely vigilant',\n",
       " '',\n",
       " 'pretend work',\n",
       " 'esg list fraudulent',\n",
       " 'time',\n",
       " 'weeks away raptor engines needed orbital flight complete installed',\n",
       " 'interview',\n",
       " '',\n",
       " 'years spacex mission',\n",
       " 'cybertruck body',\n",
       " 'humble bro \\n\\n billy sense humor irreverence big people love dogecoin',\n",
       " 'completely useless pos',\n",
       " 'palmer forgets mention wrote single line dogecoin code',\n",
       " 'ai things python javascript web stuff \\n\\n high performance tight code c c++ spiced assembly',\n",
       " '',\n",
       " '',\n",
       " 'opposite twitter better experience idea',\n",
       " '',\n",
       " 'checking',\n",
       " 'kids wrote better code nonsense script jackson sent \\n\\n said great share world experience twitter better mean \\n\\n jackson palmer tool',\n",
       " 'falsely claimed ur lame snippet python gets rid bots buddy share world',\n",
       " 'going',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4ddd6e",
   "metadata": {},
   "source": [
    "# On transforme les mots en matrice de fréquence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2514f56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sklearn) (0.24.2)\n",
      "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.7.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn->sklearn) (1.19.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -xml (c:\\users\\hp\\appdata\\local\\programs\\python\\python39\\lib\\site-packages)\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4a7397f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a258ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer()\n",
    "tf = CountVectorizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6dccc9",
   "metadata": {},
   "source": [
    "# * LDA est une méthode probabiliste, on utilise donc CountVectorizer (nombre d'apparition des mots) \n",
    "\n",
    "# * NMF est une méthode non probabiliste, on utilise donc TfidfVectorizer (poids des mots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ef64cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_lda = tf.fit_transform(clean_text) # LDA est une méthode probabiliste, on utilise donc CountVectorizer\n",
    "text_nmf = tfidf_vect.fit_transform(clean_text) # NMF est une méthode non probabiliste, on utilise donc TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368f19aa",
   "metadata": {},
   "source": [
    "On récupère la liste des features ou mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab9bd175",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms_nmf = tfidf_vect.get_feature_names()\n",
    "terms_lda = tf.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf8730a",
   "metadata": {},
   "source": [
    "Matrice TF des mots. On utilise les 15000 premiers tweets, le reste sera utilisé pour mesurer le perplexité et la cohérence du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df131a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaargh</th>\n",
       "      <th>aargh</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>aber</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablate</th>\n",
       "      <th>ablative</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zootopia</th>\n",
       "      <th>zorbix</th>\n",
       "      <th>zork</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuck</th>\n",
       "      <th>zukunft</th>\n",
       "      <th>zune</th>\n",
       "      <th>zx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 13025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aaargh  aargh  abandoned  abandoning  abdomen  aber  abide  ability  \\\n",
       "0           0      0          0           0        0     0      0        0   \n",
       "1           0      0          0           0        0     0      0        0   \n",
       "2           0      0          0           0        0     0      0        0   \n",
       "3           0      0          0           0        0     0      0        0   \n",
       "4           0      0          0           0        0     0      0        0   \n",
       "...       ...    ...        ...         ...      ...   ...    ...      ...   \n",
       "14995       0      0          0           0        0     0      0        0   \n",
       "14996       0      0          0           0        0     0      0        0   \n",
       "14997       0      0          0           0        0     0      0        0   \n",
       "14998       0      0          0           0        0     0      0        0   \n",
       "14999       0      0          0           0        0     0      0        0   \n",
       "\n",
       "       ablate  ablative  ...  zooming  zooms  zootopia  zorbix  zork  zu  \\\n",
       "0           0         0  ...        0      0         0       0     0   0   \n",
       "1           0         0  ...        0      0         0       0     0   0   \n",
       "2           0         0  ...        0      0         0       0     0   0   \n",
       "3           0         0  ...        0      0         0       0     0   0   \n",
       "4           0         0  ...        0      0         0       0     0   0   \n",
       "...       ...       ...  ...      ...    ...       ...     ...   ...  ..   \n",
       "14995       0         0  ...        0      0         0       0     0   0   \n",
       "14996       0         0  ...        0      0         0       0     0   0   \n",
       "14997       0         0  ...        0      0         0       0     0   0   \n",
       "14998       0         0  ...        0      0         0       0     0   0   \n",
       "14999       0         0  ...        0      0         0       0     0   0   \n",
       "\n",
       "       zuck  zukunft  zune  zx  \n",
       "0         0        0     0   0  \n",
       "1         0        0     0   0  \n",
       "2         0        0     0   0  \n",
       "3         0        0     0   0  \n",
       "4         0        0     0   0  \n",
       "...     ...      ...   ...  ..  \n",
       "14995     0        0     0   0  \n",
       "14996     0        0     0   0  \n",
       "14997     0        0     0   0  \n",
       "14998     0        0     0   0  \n",
       "14999     0        0     0   0  \n",
       "\n",
       "[15000 rows x 13025 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lda = pd.DataFrame(text_lda[:15000].toarray(), columns=terms_lda)\n",
    "df_lda # Affichage d'une partie de la matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bbfaea",
   "metadata": {},
   "source": [
    "Matrice TF-IDF des mots. On utilise les 15000 premiers tweets, le reste sera utilisé pour mesurer le perplexité et la cohérence du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df131a0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaargh</th>\n",
       "      <th>aargh</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abdomen</th>\n",
       "      <th>aber</th>\n",
       "      <th>abide</th>\n",
       "      <th>ability</th>\n",
       "      <th>ablate</th>\n",
       "      <th>ablative</th>\n",
       "      <th>...</th>\n",
       "      <th>zooming</th>\n",
       "      <th>zooms</th>\n",
       "      <th>zootopia</th>\n",
       "      <th>zorbix</th>\n",
       "      <th>zork</th>\n",
       "      <th>zu</th>\n",
       "      <th>zuck</th>\n",
       "      <th>zukunft</th>\n",
       "      <th>zune</th>\n",
       "      <th>zx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15000 rows × 13025 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       aaargh  aargh  abandoned  abandoning  abdomen  aber  abide  ability  \\\n",
       "0         0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "1         0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "2         0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "3         0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "4         0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "...       ...    ...        ...         ...      ...   ...    ...      ...   \n",
       "14995     0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "14996     0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "14997     0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "14998     0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "14999     0.0    0.0        0.0         0.0      0.0   0.0    0.0      0.0   \n",
       "\n",
       "       ablate  ablative  ...  zooming  zooms  zootopia  zorbix  zork   zu  \\\n",
       "0         0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "1         0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "2         0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "3         0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "4         0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "...       ...       ...  ...      ...    ...       ...     ...   ...  ...   \n",
       "14995     0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "14996     0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "14997     0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "14998     0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "14999     0.0       0.0  ...      0.0    0.0       0.0     0.0   0.0  0.0   \n",
       "\n",
       "       zuck  zukunft  zune   zx  \n",
       "0       0.0      0.0   0.0  0.0  \n",
       "1       0.0      0.0   0.0  0.0  \n",
       "2       0.0      0.0   0.0  0.0  \n",
       "3       0.0      0.0   0.0  0.0  \n",
       "4       0.0      0.0   0.0  0.0  \n",
       "...     ...      ...   ...  ...  \n",
       "14995   0.0      0.0   0.0  0.0  \n",
       "14996   0.0      0.0   0.0  0.0  \n",
       "14997   0.0      0.0   0.0  0.0  \n",
       "14998   0.0      0.0   0.0  0.0  \n",
       "14999   0.0      0.0   0.0  0.0  \n",
       "\n",
       "[15000 rows x 13025 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nmf = pd.DataFrame(text_nmf[:15000].toarray(), columns=terms_nmf)\n",
    "df_nmf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352a34c6",
   "metadata": {},
   "source": [
    "# On entraîne 2 modèles avec les méthodes LDA (Latent Dirichlet Allocation) et NMF (Non-Negative Matrix Factorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "350bf20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation, NMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f60b3c",
   "metadata": {},
   "source": [
    "# Nous allons d'abord essayer de déterminer les meilleurs paramètres pour nos modèles. Pour cela, on va utiliser la méthode GridSearchCV qui va nous permettre de tester plusieurs combinaisons de paramètres et de choisir les meilleurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7de8fb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158a9781",
   "metadata": {},
   "source": [
    "Evaluation des meilleurs paramètres pour LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c36761ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LatentDirichletAllocation(),\n",
       "             param_grid={'learning_decay': [0.5, 0.7, 0.9],\n",
       "                         'n_components': [5, 10, 15]})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_params = {'n_components': [5, 10, 15], 'learning_decay': [.5, .7, .9]} # Paramètres à tester pour LDA\n",
    "# on initialise LDA sans paramètres\n",
    "lda = LatentDirichletAllocation()\n",
    "# Initialise Grid Search \n",
    "model = GridSearchCV(lda, param_grid=search_params)\n",
    "\n",
    "# Do the Grid Search\n",
    "model.fit(df_lda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "58164cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model's Params:  {'learning_decay': 0.5, 'n_components': 5}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs paramètres pour LDA: \", model.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e106a187",
   "metadata": {},
   "source": [
    "On entraîne un modèle avec LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "949f9840",
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LatentDirichletAllocation(n_components=5, max_iter=5,\n",
    "                                learning_method='online', learning_offset=50., random_state=0, learning_decay=0.5).fit(text_lda)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff20c2cf",
   "metadata": {},
   "source": [
    "On entraîne un modèle avec NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9442c146",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=5, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5, init='nndsvd').fit(text_nmf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c5487f",
   "metadata": {},
   "source": [
    "# On affiche les 10 mots les plus significatifs de chaque topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39c4058f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------LDA:--------------------------------\n",
      "Topic 0: cars tesla future company design looks battery life low kids\n",
      "Topic 1: tesla people new soon right coming space lot work time\n",
      "Topic 2: actually know think years article boring definitely mission called little\n",
      "Topic 3: launch rocket high landing test exactly flight want air change\n",
      "Topic 4: model tesla great car falcon spacex year dragon love rocket\n",
      "---------------------NMF:--------------------------------\n",
      "Topic 0: exactly love said question point looking sigh makes monday money\n",
      "Topic 1: sure hope way pretty sounds year probably need early favorite\n",
      "Topic 2: great idea work game team sounds thread pretty song shot\n",
      "Topic 3: soon coming real improvements year update fun software feature sorry\n",
      "Topic 4: tesla team model car work year cars spacex production time\n"
     ]
    }
   ],
   "source": [
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print (\"Topic {}:\".format(topic_idx), end=' ')\n",
    "        print (\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "\n",
    "\n",
    "nb_top_words = 10\n",
    "print(\"---------------------LDA:--------------------------------\")\n",
    "display_topics(lda, terms_lda, nb_top_words)\n",
    "print(\"---------------------NMF:--------------------------------\")\n",
    "display_topics(nmf, terms_nmf, nb_top_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a715f7",
   "metadata": {},
   "source": [
    "# Evaluation des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555f2723",
   "metadata": {},
   "source": [
    "Perplexité du modèle LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "14efaa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lda = pd.DataFrame(text_lda[15000:].toarray(), columns=terms_lda)\n",
    "test_nmf = pd.DataFrame(text_nmf[15000:].toarray(), columns=terms_nmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0565facb",
   "metadata": {},
   "source": [
    "* Perplexité du modèle par rapport à la base test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ee0ecfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31354.474622092715"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.perplexity(test_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10744ffa",
   "metadata": {},
   "source": [
    "* Perplexité du modèle par rapport à la base d'entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04e78966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7672.461000310403"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda.perplexity(text_lda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "f6246b25e200e4c5124e3e61789ac81350562f0761bbcf92ad9e48654207659c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
